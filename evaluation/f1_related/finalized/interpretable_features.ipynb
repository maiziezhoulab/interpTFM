{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c86cdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique cell_ids across 60 shards: 81,236\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Metadata: cell-gene pairs\n",
    "meta_df = pd.read_csv(\n",
    "    \"/maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/gene_ids/shard_0/cell_gene_pairs.txt\",\n",
    "    sep=\"\\t\", header=None, names=[\"cell_id\", \"gene_id\"]\n",
    ")\n",
    "\n",
    "# Load your main dataframe\n",
    "f1_df = pd.read_csv(\n",
    "    \"/maiziezhou_lab2/yunfei/Projects/FM_temp/interGFM/output/test/heldout_top_pairings.csv\",\n",
    "    index_col=0\n",
    ")\n",
    "f1_df[\"concept\"] = f1_df[\"concept\"].astype(str).str.strip().str.strip('\"')\n",
    "# Load the file with GO terms\n",
    "go_df = pd.read_csv(\"/maiziezhou_lab2/yunfei/Projects/interpTFM/gprofiler_annotation/cosmx_lung_human_gp_go_kegg_reactome.csv\", usecols=[\"term_name\", \"term_id\"])\n",
    "\n",
    "# Merge: match f1_df['concept'] with go_df['term_name']\n",
    "f1_df = f1_df.merge(go_df, left_on=\"concept\", right_on=\"term_name\", how=\"left\")\n",
    "\n",
    "# Activations\n",
    "###### this is wrong, let's try to use the SAE latents to replace thiss\n",
    "# acts_df = pd.read_parquet(\"/maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/activations/layer_4/shard_0/sae_latents.parquet\")\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"/maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/activations/layer_4\"\n",
    "shards = [f\"shard_{i}\" for i in range(60)]\n",
    "\n",
    "all_cell_ids = set()\n",
    "missing = []\n",
    "\n",
    "for sh in shards:\n",
    "    path = os.path.join(base_dir, sh, \"sae_latents.parquet\")\n",
    "    if not os.path.exists(path):\n",
    "        missing.append(sh)\n",
    "        continue\n",
    "    # read only the 'cell_id' column to save memory\n",
    "    df_ids = pd.read_parquet(path, columns=[\"cell_id\"])\n",
    "    all_cell_ids.update(df_ids[\"cell_id\"].astype(str).unique())\n",
    "\n",
    "all_cell_ids = pd.Index(sorted(all_cell_ids))\n",
    "print(f\"Total unique cell_ids across {len(shards)-len(missing)} shards: {len(all_cell_ids):,}\")\n",
    "if missing:\n",
    "    print(\"Missing shards (no file found):\", missing[:10], \"...\" if len(missing) > 10 else \"\")\n",
    "\n",
    "# Optional: save list\n",
    "# pd.Series(all_cell_ids, name=\"cell_id\").to_csv(\"all_cell_ids.csv\", index=False)\n",
    "\n",
    "# Load h5ad to get cell types\n",
    "adata = sc.read_h5ad(\"/maiziezhou_lab2/yunfei/Projects/FM_temp/InterPLM/interplm/ge_shards/cosmx_human_lung_sec8.h5ad\")\n",
    "# /maiziezhou_lab2/yunfei/Projects/FM_temp/datasets/cosmx/lung/cosmx_human_lung.h5ad\n",
    "\n",
    "\n",
    "celltype_map = adata.obs[\"author_cell_type\"].to_dict()  # dict: cell_id → cell_type\n",
    "\n",
    "# Add cell_type to meta_df\n",
    "meta_df[\"cell_type\"] = meta_df[\"cell_id\"].map(celltype_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13795f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96_1-6</td>\n",
       "      <td>&lt;cls&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96_1-6</td>\n",
       "      <td>ABL1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96_1-6</td>\n",
       "      <td>ADGRA3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96_1-6</td>\n",
       "      <td>ADGRE5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96_1-6</td>\n",
       "      <td>ADM2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516875</th>\n",
       "      <td>3880_20-3</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516876</th>\n",
       "      <td>3880_20-3</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516877</th>\n",
       "      <td>3880_20-3</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516878</th>\n",
       "      <td>3880_20-3</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516879</th>\n",
       "      <td>3880_20-3</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516880 rows × 4098 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cell_id gene_id    0         1    2    3    4    5    6         7  \\\n",
       "0          96_1-6   <cls>  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "1          96_1-6    ABL1  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.048794   \n",
       "2          96_1-6  ADGRA3  0.0  0.002219  0.0  0.0  0.0  0.0  0.0  0.067180   \n",
       "3          96_1-6  ADGRE5  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "4          96_1-6    ADM2  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "...           ...     ...  ...       ...  ...  ...  ...  ...  ...       ...   \n",
       "516875  3880_20-3   <pad>  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "516876  3880_20-3   <pad>  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "516877  3880_20-3   <pad>  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "516878  3880_20-3   <pad>  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "516879  3880_20-3   <pad>  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000   \n",
       "\n",
       "        ...  4086  4087  4088  4089  4090  4091  4092  4093  4094  4095  \n",
       "0       ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1       ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2       ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3       ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4       ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "516875  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "516876  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "516877  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "516878  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "516879  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[516880 rows x 4098 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec755d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        208\n",
       "1       2430\n",
       "2         71\n",
       "3         71\n",
       "4       1725\n",
       "        ... \n",
       "1788    2296\n",
       "1789    3760\n",
       "1790    1309\n",
       "1791     238\n",
       "1792     238\n",
       "Name: feature, Length: 1793, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df[\"feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608de62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for sanity check of why are we losing cells\n",
    "\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import scanpy as sc\n",
    "\n",
    "# # ============ 0) helpers ============\n",
    "# def normalize_feat_name(x):\n",
    "#     s = str(x).strip()\n",
    "#     m = re.search(r'(\\d+)$', s)\n",
    "#     if m:\n",
    "#         try:\n",
    "#             return int(m.group(1))\n",
    "#         except ValueError:\n",
    "#             return s\n",
    "#     return s\n",
    "\n",
    "# def peek(name, obj, n=5):\n",
    "#     try:\n",
    "#         print(f\"[peek] {name} head:\")\n",
    "#         print(obj.head(n))\n",
    "#     except Exception as e:\n",
    "#         print(f\"[peek] {name} head: <error {e}>\")\n",
    "\n",
    "# # -------- Initial sanity on inputs --------\n",
    "# print(\"\\n=== INPUT SANITY ===\")\n",
    "# if isinstance(adata, sc.AnnData):\n",
    "#     print(f\"[info] adata: n_obs={adata.n_obs}, n_vars={adata.n_vars}\")\n",
    "# else:\n",
    "#     print(\"[warn] 'adata' is not an AnnData\")\n",
    "\n",
    "# print(f\"[info] acts_df shape: {acts_df.shape}\")\n",
    "# print(f\"[info] acts_df columns (first 12): {list(acts_df.columns)[:12]}\")\n",
    "# print(f\"[info] acts_df cell_id nunique: {acts_df['cell_id'].nunique():,}\")\n",
    "# print(f\"[info] acts_df example cell_ids: {acts_df['cell_id'].astype(str).unique()[:3]}\")\n",
    "# print(f\"[info] acts_df gene_id nunique: {acts_df['gene_id'].nunique():,}\")\n",
    "\n",
    "# # Are there NA cell_ids?\n",
    "# na_cells = acts_df['cell_id'].isna().sum()\n",
    "# print(f\"[info] acts_df NA cell_id count: {na_cells}\")\n",
    "# if na_cells:\n",
    "#     print(\"[warn] NA cell_ids found; those rows will be dropped during groupby/merge.\")\n",
    "\n",
    "# # ============ 1) filter mappings ============\n",
    "# F1_THRESHOLD = 0.5\n",
    "# f1_interpretable = f1_df.query(\"f1 >= @F1_THRESHOLD\").copy()\n",
    "# print(f\"\\n=== MAPPINGS ===\")\n",
    "# print(f\"[info] mappings with F1 ≥ {F1_THRESHOLD}: {len(f1_interpretable):,}\")\n",
    "# peek(\"f1_interpretable\", f1_interpretable)\n",
    "\n",
    "# if f1_interpretable.empty:\n",
    "#     raise ValueError(\"No (feature, concept) pairs passed the F1 threshold.\")\n",
    "\n",
    "# f1_interpretable[\"feature_norm\"] = f1_interpretable[\"feature\"].apply(normalize_feat_name)\n",
    "\n",
    "# # ============ 2) select feature columns from acts_df ============\n",
    "# non_feature_cols = {\"cell_id\", \"gene_id\"}\n",
    "# all_cols = list(acts_df.columns)\n",
    "# feature_cols_raw = [c for c in all_cols if c not in non_feature_cols]\n",
    "# feature_cols_norm = [normalize_feat_name(c) for c in feature_cols_raw]\n",
    "# colname_to_norm = dict(zip(feature_cols_raw, feature_cols_norm))\n",
    "\n",
    "# feat_in_map = set(f1_interpretable[\"feature_norm\"].unique())\n",
    "# feat_in_acts = set(feature_cols_norm)\n",
    "# intersection_norm = sorted(feat_in_map.intersection(feat_in_acts))\n",
    "\n",
    "# print(f\"\\n=== FEATURE INTERSECTION ===\")\n",
    "# print(f\"[info] interpretable features in mapping: {len(feat_in_map):,}\")\n",
    "# print(f\"[info] feature columns in acts_df:        {len(feat_in_acts):,}\")\n",
    "# print(f\"[info] intersection (used features):      {len(intersection_norm):,}\")\n",
    "# if not intersection_norm:\n",
    "#     print(\"[warn] Example mapped feats:\", list(feat_in_map)[:10])\n",
    "#     print(\"[warn] Example acts_df feats (norm):\", list(feat_in_acts)[:10])\n",
    "#     raise ValueError(\"Feature/column mismatch after normalization.\")\n",
    "\n",
    "# keep_feature_cols = [orig for orig, norm in colname_to_norm.items() if norm in intersection_norm]\n",
    "\n",
    "# print(f\"[info] keeping {len(keep_feature_cols):,} feature columns (out of {len(feature_cols_raw):,})\")\n",
    "# if len(keep_feature_cols) < 10:\n",
    "#     print(\"[peek] keep_feature_cols:\", keep_feature_cols)\n",
    "\n",
    "# # ============ 3) melt acts_df on kept feature columns ============\n",
    "# print(\"\\n=== MELT ===\")\n",
    "# acts_sel = acts_df[[\"cell_id\", \"gene_id\"] + keep_feature_cols].copy()\n",
    "\n",
    "# # Basic sanity of tokens per cell (before melt)\n",
    "# tok_per_cell = acts_sel.groupby(\"cell_id\", sort=False)[\"gene_id\"].size()\n",
    "# print(f\"[info] tokens per cell: mean={tok_per_cell.mean():.1f}, median={tok_per_cell.median():.1f}, min={tok_per_cell.min()}, max={tok_per_cell.max()}\")\n",
    "\n",
    "# acts_long = (\n",
    "#     acts_sel\n",
    "#     .melt(id_vars=[\"cell_id\", \"gene_id\"], var_name=\"feature_col\", value_name=\"activation\")\n",
    "# )\n",
    "# acts_long[\"feature_norm\"] = acts_long[\"feature_col\"].map(colname_to_norm)\n",
    "\n",
    "# print(f\"[info] acts_long shape: {acts_long.shape}\")\n",
    "# print(f\"[info] acts_long cells nunique: {acts_long['cell_id'].nunique():,}\")\n",
    "# print(f\"[info] acts_long features nunique: {acts_long['feature_norm'].nunique():,}\")\n",
    "# peek(\"acts_long\", acts_long)\n",
    "\n",
    "# # ============ 4) join with (feature -> concepts) mappings ============\n",
    "# print(\"\\n=== MERGE FEATURES→CONCEPTS ===\")\n",
    "# map_small = f1_interpretable[[\"feature_norm\", \"concept\", \"f1\"]].copy()\n",
    "# acts_concept_df = acts_long.merge(map_small, on=\"feature_norm\", how=\"inner\")\n",
    "\n",
    "# print(f\"[info] rows after merge: {len(acts_concept_df):,}\")\n",
    "# print(f\"[info] cells after merge (nunique): {acts_concept_df['cell_id'].nunique():,}\")\n",
    "# print(f\"[info] concepts used: {acts_concept_df['concept'].nunique():,}\")\n",
    "# # which concepts are most frequent?\n",
    "# print(\"[info] top concepts by count:\")\n",
    "# print(acts_concept_df[\"concept\"].value_counts().head(10))\n",
    "\n",
    "# if acts_concept_df.empty:\n",
    "#     raise ValueError(\"Empty after merge — check intersections above.\")\n",
    "\n",
    "# # ============ 5) aggregate to cell × concept ============\n",
    "# print(\"\\n=== AGGREGATE TO CELL × CONCEPT ===\")\n",
    "# concept_matrix = (\n",
    "#     acts_concept_df\n",
    "#     .groupby([\"cell_id\", \"concept\"], sort=False)[\"activation\"]\n",
    "#     .mean()\n",
    "#     .unstack(fill_value=0)\n",
    "#     .sort_index(axis=0)\n",
    "#     .sort_index(axis=1)\n",
    "# )\n",
    "# print(f\"[info] concept_matrix shape (cells × concepts): {concept_matrix.shape}\")\n",
    "# print(f\"[info] concept_matrix cell_id nunique: {concept_matrix.index.nunique():,}\")\n",
    "# print(f\"[info] concept_matrix concepts: {concept_matrix.shape[1]:,}\")\n",
    "\n",
    "# # optional: how many cells are all-zero across concepts (no interpretable features fired)?\n",
    "# zero_rows = (concept_matrix.sum(axis=1) == 0).sum()\n",
    "# print(f\"[info] cells with all-zero concept vector: {zero_rows:,} ({zero_rows/len(concept_matrix):.2%})\")\n",
    "\n",
    "# # ============ 6) build new AnnData with concept features ============\n",
    "# print(\"\\n=== BUILD NEW AnnData ===\")\n",
    "# if isinstance(adata, sc.AnnData):\n",
    "#     # ensure same dtype for matching (string)\n",
    "#     acts_cells = concept_matrix.index.astype(str)\n",
    "#     adata_cells = adata.obs_names.astype(str)\n",
    "\n",
    "#     common_cells = adata_cells.intersection(acts_cells)\n",
    "#     print(f\"[info] adata cells total: {adata.n_obs:,}\")\n",
    "#     print(f\"[info] cells in concept_matrix: {concept_matrix.index.nunique():,}\")\n",
    "#     print(f\"[info] cells in intersection:  {len(common_cells):,}\")\n",
    "\n",
    "#     # show a few examples of cells that failed to match (if large drop)\n",
    "#     if len(common_cells) < concept_matrix.index.nunique():\n",
    "#         diff = set(acts_cells).difference(set(common_cells))\n",
    "#         print(f\"[warn] {len(diff):,} cells in concept_matrix not found in adata.obs_names (showing up to 5):\")\n",
    "#         print(list(diff)[:5])\n",
    "\n",
    "#     # align concept_matrix order to adata\n",
    "#     concept_matrix = concept_matrix.loc[concept_matrix.index.astype(str).isin(common_cells)]\n",
    "#     concept_matrix = concept_matrix.reindex(adata.obs_names.astype(str).intersection(concept_matrix.index.astype(str)))\n",
    "\n",
    "#     adata_concept = sc.AnnData(\n",
    "#         X=concept_matrix.values,\n",
    "#         obs=adata.obs.loc[concept_matrix.index].copy(),\n",
    "#         var=pd.DataFrame(index=concept_matrix.columns)\n",
    "#     )\n",
    "# else:\n",
    "#     print(\"[warn] 'adata' not provided as AnnData; building from concept_matrix only.\")\n",
    "#     adata_concept = sc.AnnData(\n",
    "#         X=concept_matrix.values,\n",
    "#         obs=pd.DataFrame(index=concept_matrix.index),\n",
    "#         var=pd.DataFrame(index=concept_matrix.columns)\n",
    "#     )\n",
    "\n",
    "# adata_concept.uns[\"concept_feature_build\"] = {\n",
    "#     \"F1_THRESHOLD\": F1_THRESHOLD,\n",
    "#     \"aggfunc\": \"mean\",\n",
    "#     \"n_cells\": adata_concept.n_obs,\n",
    "#     \"n_concepts\": adata_concept.n_vars,\n",
    "# }\n",
    "\n",
    "# print(\"\\n=== SUMMARY ===\")\n",
    "# print(f\"[ok] adata_concept: n_obs={adata_concept.n_obs:,}, n_vars={adata_concept.n_vars:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba31d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shard_0: cells=1,349, concepts=393\n",
      "shard_1: cells=1,407, concepts=393\n",
      "shard_2: cells=1,337, concepts=393\n",
      "shard_3: cells=1,352, concepts=393\n",
      "shard_4: cells=1,334, concepts=393\n",
      "shard_5: cells=1,350, concepts=393\n",
      "shard_6: cells=1,258, concepts=393\n",
      "shard_7: cells=1,393, concepts=393\n",
      "shard_8: cells=1,327, concepts=393\n",
      "shard_9: cells=1,325, concepts=393\n",
      "shard_10: cells=1,381, concepts=393\n",
      "shard_11: cells=1,422, concepts=393\n",
      "shard_12: cells=1,362, concepts=393\n",
      "shard_13: cells=1,358, concepts=393\n",
      "shard_14: cells=1,284, concepts=393\n",
      "shard_15: cells=1,339, concepts=393\n",
      "shard_16: cells=1,352, concepts=393\n",
      "shard_17: cells=1,354, concepts=393\n",
      "shard_18: cells=1,392, concepts=393\n",
      "shard_19: cells=1,324, concepts=393\n",
      "shard_20: cells=1,349, concepts=393\n",
      "shard_21: cells=1,369, concepts=393\n",
      "shard_22: cells=1,306, concepts=393\n",
      "shard_23: cells=1,374, concepts=393\n",
      "shard_24: cells=1,381, concepts=393\n",
      "shard_25: cells=1,318, concepts=393\n",
      "shard_26: cells=1,384, concepts=393\n",
      "shard_27: cells=1,359, concepts=393\n",
      "shard_28: cells=1,315, concepts=393\n",
      "shard_29: cells=1,343, concepts=393\n",
      "shard_30: cells=1,388, concepts=393\n",
      "shard_31: cells=1,325, concepts=393\n",
      "shard_32: cells=1,392, concepts=393\n",
      "shard_33: cells=1,343, concepts=393\n",
      "shard_34: cells=1,333, concepts=393\n",
      "shard_35: cells=1,381, concepts=393\n",
      "shard_36: cells=1,341, concepts=393\n",
      "shard_37: cells=1,357, concepts=393\n",
      "shard_38: cells=1,357, concepts=393\n",
      "shard_39: cells=1,375, concepts=393\n",
      "shard_40: cells=1,450, concepts=393\n",
      "shard_41: cells=1,378, concepts=393\n",
      "shard_42: cells=1,375, concepts=393\n",
      "shard_43: cells=1,388, concepts=393\n",
      "shard_44: cells=1,325, concepts=393\n",
      "shard_45: cells=1,355, concepts=393\n",
      "shard_46: cells=1,365, concepts=393\n",
      "shard_47: cells=1,263, concepts=393\n",
      "shard_48: cells=1,358, concepts=393\n",
      "shard_49: cells=1,389, concepts=393\n",
      "shard_50: cells=1,349, concepts=393\n",
      "shard_51: cells=1,278, concepts=393\n",
      "shard_52: cells=1,359, concepts=393\n",
      "shard_53: cells=1,459, concepts=393\n",
      "shard_54: cells=1,378, concepts=393\n",
      "shard_55: cells=1,336, concepts=393\n",
      "shard_56: cells=1,371, concepts=393\n",
      "shard_57: cells=1,362, concepts=393\n",
      "shard_58: cells=1,320, concepts=393\n",
      "shard_59: cells=1,288, concepts=393\n",
      "\n",
      "Full concept matrix: cells=81,236, concepts=393\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "# ---- helpers ----\n",
    "def normalize_feat_name(x):\n",
    "    s = str(x).strip()\n",
    "    m = re.search(r'(\\d+)$', s)\n",
    "    if m:\n",
    "        try: return int(m.group(1))\n",
    "        except ValueError: return s\n",
    "    return s\n",
    "\n",
    "F1_THRESHOLD = 0.5\n",
    "f1_interpretable = f1_df.query(\"f1 >= @F1_THRESHOLD\").copy()\n",
    "f1_interpretable[\"feature_norm\"] = f1_interpretable[\"feature\"].apply(normalize_feat_name)\n",
    "map_small = f1_interpretable[[\"feature_norm\", \"concept\", \"f1\"]].copy()\n",
    "\n",
    "def shard_concept_matrix(latents_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"latents_df has columns: cell_id, gene_id, 0..D-1 (latent dims)\"\"\"\n",
    "    non_feature = {\"cell_id\", \"gene_id\"}\n",
    "    feat_cols_raw = [c for c in latents_df.columns if c not in non_feature]\n",
    "    feat_cols_norm = [normalize_feat_name(c) for c in feat_cols_raw]\n",
    "    colname_to_norm = dict(zip(feat_cols_raw, feat_cols_norm))\n",
    "\n",
    "    feat_in_map = set(map_small[\"feature_norm\"])\n",
    "    inter = sorted(set(feat_cols_norm).intersection(feat_in_map))\n",
    "    if not inter:\n",
    "        return None\n",
    "\n",
    "    keep_cols = [orig for orig, norm in colname_to_norm.items() if norm in inter]\n",
    "    df = latents_df[[\"cell_id\", \"gene_id\"] + keep_cols].copy()\n",
    "\n",
    "    long = df.melt(id_vars=[\"cell_id\", \"gene_id\"], var_name=\"feature_col\", value_name=\"activation\")\n",
    "    long[\"feature_norm\"] = long[\"feature_col\"].map(colname_to_norm)\n",
    "\n",
    "    merged = long.merge(map_small, on=\"feature_norm\", how=\"inner\")\n",
    "    if merged.empty:\n",
    "        return None\n",
    "\n",
    "    # aggregate over tokens and features → cell × concept\n",
    "    mat = (\n",
    "        merged.groupby([\"cell_id\", \"concept\"])[\"activation\"]\n",
    "              .mean()                        # or .sum() if you prefer accumulation\n",
    "              .unstack(fill_value=0)\n",
    "    )\n",
    "    return mat\n",
    "\n",
    "# ---- iterate shards ----\n",
    "base_dir = \"/maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/activations/layer_4\"\n",
    "shards = [f\"shard_{i}\" for i in range(60)]\n",
    "concept_mats = []\n",
    "missing = []\n",
    "\n",
    "for sh in shards:\n",
    "    path = os.path.join(base_dir, sh, \"sae_latents.parquet\")\n",
    "    if not os.path.exists(path):\n",
    "        missing.append(sh)\n",
    "        continue\n",
    "    latents_df = pd.read_parquet(path)  # this includes cell_id, gene_id, and latent dims\n",
    "    cm = shard_concept_matrix(latents_df)\n",
    "    if cm is not None and len(cm):\n",
    "        concept_mats.append(cm)\n",
    "        print(f\"{sh}: cells={cm.shape[0]:,}, concepts={cm.shape[1]:,}\")\n",
    "    else:\n",
    "        print(f\"{sh}: no interpretable features matched; skipping\")\n",
    "\n",
    "# combine all cells\n",
    "full_concept = pd.concat(concept_mats, axis=0)\n",
    "full_concept = full_concept[~full_concept.index.duplicated(keep=\"first\")]\n",
    "print(f\"\\nFull concept matrix: cells={full_concept.shape[0]:,}, concepts={full_concept.shape[1]:,}\")\n",
    "if missing:\n",
    "    print(\"Missing shards:\", missing[:10], \"...\" if len(missing) > 10 else \"\")\n",
    "\n",
    "# ---- build AnnData aligned to original adata (optional) ----\n",
    "common = adata.obs_names.astype(str).intersection(full_concept.index.astype(str))\n",
    "full_concept = full_concept.loc[common].reindex(adata.obs_names.astype(str).intersection(common))\n",
    "\n",
    "adata_concept = sc.AnnData(\n",
    "    X=full_concept.values,\n",
    "    obs=adata.obs.loc[full_concept.index].copy(),\n",
    "    var=pd.DataFrame(index=full_concept.columns),\n",
    ")\n",
    "adata_concept.uns[\"concept_feature_build\"] = {\n",
    "    \"F1_THRESHOLD\": F1_THRESHOLD,\n",
    "    \"n_cells\": adata_concept.n_obs,\n",
    "    \"n_concepts\": adata_concept.n_vars,\n",
    "    \"n_shards\": len(shards),\n",
    "}\n",
    "\n",
    "# optional save\n",
    "# adata_concept.write_h5ad(\"/maiziezhou_lab2/yunfei/Projects/interpTFM/adata_interpretable_concepts_full.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68551c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 81236 × 393\n",
       "    obs: 'AspectRatio', 'CenterX_global_px', 'CenterY_global_px', 'Width', 'Height', 'Mean.MembraneStain', 'Max.MembraneStain', 'Mean.PanCK', 'Max.PanCK', 'Mean.CD45', 'Max.CD45', 'Mean.CD3', 'Max.CD3', 'Mean.DAPI', 'Max.DAPI', 'niche', 'image_id', 'cell_ID', 'sex_ontology_term_id', 'assay_ontology_term_id', 'organism_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'tissue_type', 'condition_id', 'sample_id', 'donor_id', 'author_cell_type', 'library_key', 'region', 'assay', 'organism', 'sex', 'tissue', 'dataset', 'x', 'y', 'nicheformer_split', '_scvi_batch', '_scvi_labels', 'shards'\n",
       "    uns: 'concept_feature_build'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c42b404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional save\n",
    "adata_concept.write_h5ad(\"/maiziezhou_lab2/yunfei/Projects/interpTFM/evaluation/ccc/data/adata_interpretable_concepts_sec8.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def7d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "adata_concept = sc.read_h5ad(\"/maiziezhou_lab2/yunfei/Projects/interpTFM/evaluation/ccc/data/adata_interpretable_concepts.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c18a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1349 × 393\n",
       "    obs: 'AspectRatio', 'CenterX_global_px', 'CenterY_global_px', 'Width', 'Height', 'Mean.MembraneStain', 'Max.MembraneStain', 'Mean.PanCK', 'Max.PanCK', 'Mean.CD45', 'Max.CD45', 'Mean.CD3', 'Max.CD3', 'Mean.DAPI', 'Max.DAPI', 'niche', 'image_id', 'cell_ID', 'sex_ontology_term_id', 'assay_ontology_term_id', 'organism_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'tissue_type', 'condition_id', 'sample_id', 'donor_id', 'author_cell_type', 'library_key', 'region', 'assay', 'organism', 'sex', 'tissue', 'dataset', 'x', 'y', 'nicheformer_split', '_scvi_batch', '_scvi_labels', 'shards'\n",
       "    uns: 'concept_feature_build'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8e6f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CD4-positive, alpha-beta T cell differentiation involved in immune response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD4-positive, alpha-beta T cell proliferation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8-positive, alpha-beta T cell activation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fc-gamma receptor signaling pathway</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G protein-coupled receptor binding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tumor necrosis factor receptor activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type II transforming growth factor beta receptor binding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vascular process in circulatory system</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ventricular cardiac muscle tissue morphogenesis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wound healing</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [CD4-positive, alpha-beta T cell differentiation involved in immune response, CD4-positive, alpha-beta T cell proliferation, CD8-positive, alpha-beta T cell activation, Fc-gamma receptor signaling pathway, G protein-coupled receptor binding, G protein-coupled receptor signaling pathway, Golgi apparatus, I-kappaB phosphorylation, MAPK cascade, MHC class II protein complex assembly, activation of protein kinase activity, adherens junction, alpha-beta T cell activation, alpha-beta T cell activation involved in immune response, antigen processing and presentation of peptide or polysaccharide antigen via MHC class II, calcium-mediated signaling, camera-type eye development, canonical NF-kappaB signal transduction, canonical Wnt signaling pathway, carbohydrate binding, carbohydrate derivative binding, carboxylic acid binding, cardiac chamber development, cardiac chamber morphogenesis, cell adhesion mediated by integrin, cell-cell fusion, cellular response to interleukin-2, cellular response to interleukin-4, cellular response to ionizing radiation, cellular response to low-density lipoprotein particle stimulus, cellular response to mechanical stimulus, cellular response to nitrogen compound, cellular response to oxidative stress, cellular response to oxygen levels, cellular response to oxygen-containing compound, cellular response to starvation, cellular response to steroid hormone stimulus, cellular response to transforming growth factor beta stimulus, cytokine receptor activity, cytoplasmic pattern recognition receptor signaling pathway, cytoplasmic vesicle membrane, cytoskeleton organization, dendritic cell antigen processing and presentation, dendritic cell apoptotic process, detection of biotic stimulus, digestive system process, digestive tract development, disordered domain specific binding, disruption of anatomical structure in another organism, disruption of cell in another organism, early endosome, embryo development, embryo development ending in birth or egg hatching, embryo implantation, embryonic digestive tract development, embryonic morphogenesis, embryonic organ development, endocrine pancreas development, endocrine process, endothelial cell apoptotic process, endothelial cell chemotaxis, endothelial cell development, endothelial cell migration, endothelial cell proliferation, epiboly, epithelial cell apoptotic process, epithelial cell differentiation, epithelial tube formation, establishment of localization, establishment of protein localization to extracellular region, exogenous protein binding, extracellular matrix assembly, extrinsic apoptotic signaling pathway via death domain receptors, fibroblast growth factor receptor signaling pathway, glial cell activation, glial cell differentiation, glial cell migration, granulocyte macrophage colony-stimulating factor production, hematopoietic or lymphoid organ development, hormone receptor binding, humoral immune response, humoral immune response mediated by circulating immunoglobulin, immune response-regulating signaling pathway, immune system process, immunological synapse formation, inorganic ion homeostasis, insulin-like growth factor binding, insulin-like growth factor binding protein complex, integrin complex, interleukin-1 beta production, interleukin-12 production, interleukin-12-mediated signaling pathway, interleukin-13 production, interleukin-2 production, interleukin-27-mediated signaling pathway, interleukin-3-mediated signaling pathway, intermediate filament-based process, intracellular calcium ion homeostasis, intracellular signaling cassette, leukocyte activation, ...]\n",
       "\n",
       "[393 rows x 0 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_concept.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9c967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7552874"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_concept.X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8b5972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89950"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.count_nonzero(adata_concept.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07425df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16966672136744398"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "89950 / (1349*393)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "092e1673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_concept.X.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c401b4",
   "metadata": {},
   "source": [
    "# if we want full lung cancer data with more sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "230e94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load h5ad to get cell types\n",
    "adata = sc.read_h5ad(\"/maiziezhou_lab2/yunfei/Projects/FM_temp/datasets/cosmx/lung/cosmx_human_lung.h5ad\")\n",
    "# /maiziezhou_lab2/yunfei/Projects/FM_temp/datasets/cosmx/lung/cosmx_human_lung.h5ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b990ad5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AspectRatio</th>\n",
       "      <th>CenterX_global_px</th>\n",
       "      <th>CenterY_global_px</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean.MembraneStain</th>\n",
       "      <th>Max.MembraneStain</th>\n",
       "      <th>Mean.PanCK</th>\n",
       "      <th>Max.PanCK</th>\n",
       "      <th>Mean.CD45</th>\n",
       "      <th>...</th>\n",
       "      <th>assay</th>\n",
       "      <th>organism</th>\n",
       "      <th>sex</th>\n",
       "      <th>tissue</th>\n",
       "      <th>dataset</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>nicheformer_split</th>\n",
       "      <th>_scvi_batch</th>\n",
       "      <th>_scvi_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_1</th>\n",
       "      <td>1.34</td>\n",
       "      <td>4215.888889</td>\n",
       "      <td>158847.666667</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>3473</td>\n",
       "      <td>7354</td>\n",
       "      <td>715</td>\n",
       "      <td>5755</td>\n",
       "      <td>361</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>4215.888889</td>\n",
       "      <td>158847.666667</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_1</th>\n",
       "      <td>1.45</td>\n",
       "      <td>6092.888889</td>\n",
       "      <td>158834.666667</td>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "      <td>3895</td>\n",
       "      <td>13832</td>\n",
       "      <td>18374</td>\n",
       "      <td>53158</td>\n",
       "      <td>260</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>6092.888889</td>\n",
       "      <td>158834.666667</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_1</th>\n",
       "      <td>1.62</td>\n",
       "      <td>7214.888889</td>\n",
       "      <td>158843.666667</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>2892</td>\n",
       "      <td>6048</td>\n",
       "      <td>3265</td>\n",
       "      <td>37522</td>\n",
       "      <td>378</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>7214.888889</td>\n",
       "      <td>158843.666667</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_1</th>\n",
       "      <td>0.47</td>\n",
       "      <td>7418.888889</td>\n",
       "      <td>158813.666667</td>\n",
       "      <td>48</td>\n",
       "      <td>102</td>\n",
       "      <td>6189</td>\n",
       "      <td>16091</td>\n",
       "      <td>485</td>\n",
       "      <td>964</td>\n",
       "      <td>679</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>7418.888889</td>\n",
       "      <td>158813.666667</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7446.888889</td>\n",
       "      <td>158845.666667</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>8138</td>\n",
       "      <td>19281</td>\n",
       "      <td>549</td>\n",
       "      <td>874</td>\n",
       "      <td>566</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>7446.888889</td>\n",
       "      <td>158845.666667</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999_20-2</th>\n",
       "      <td>1.02</td>\n",
       "      <td>-18135.000000</td>\n",
       "      <td>10850.777778</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>7430</td>\n",
       "      <td>9572</td>\n",
       "      <td>370</td>\n",
       "      <td>962</td>\n",
       "      <td>450</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>-18135.000000</td>\n",
       "      <td>10850.777778</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000_20-2</th>\n",
       "      <td>1.71</td>\n",
       "      <td>-18088.000000</td>\n",
       "      <td>10846.777778</td>\n",
       "      <td>60</td>\n",
       "      <td>35</td>\n",
       "      <td>8362</td>\n",
       "      <td>11209</td>\n",
       "      <td>161</td>\n",
       "      <td>2024</td>\n",
       "      <td>572</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>-18088.000000</td>\n",
       "      <td>10846.777778</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001_20-2</th>\n",
       "      <td>2.75</td>\n",
       "      <td>-19112.000000</td>\n",
       "      <td>10846.777778</td>\n",
       "      <td>99</td>\n",
       "      <td>36</td>\n",
       "      <td>5158</td>\n",
       "      <td>10180</td>\n",
       "      <td>634</td>\n",
       "      <td>2166</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>-19112.000000</td>\n",
       "      <td>10846.777778</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003_20-2</th>\n",
       "      <td>2.12</td>\n",
       "      <td>-19551.000000</td>\n",
       "      <td>10841.777778</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>6339</td>\n",
       "      <td>9804</td>\n",
       "      <td>211</td>\n",
       "      <td>570</td>\n",
       "      <td>488</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>-19551.000000</td>\n",
       "      <td>10841.777778</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004_20-2</th>\n",
       "      <td>2.33</td>\n",
       "      <td>-17185.000000</td>\n",
       "      <td>10839.777778</td>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "      <td>3491</td>\n",
       "      <td>5600</td>\n",
       "      <td>203</td>\n",
       "      <td>481</td>\n",
       "      <td>335</td>\n",
       "      <td>...</td>\n",
       "      <td>NanoString digital spatial profiling</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>lung</td>\n",
       "      <td>nanostring_cosmx_human_lung</td>\n",
       "      <td>-17185.000000</td>\n",
       "      <td>10839.777778</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>771236 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AspectRatio  CenterX_global_px  CenterY_global_px  Width  Height  \\\n",
       "1_1               1.34        4215.888889      158847.666667     47      35   \n",
       "2_1               1.45        6092.888889      158834.666667     87      60   \n",
       "3_1               1.62        7214.888889      158843.666667     68      42   \n",
       "4_1               0.47        7418.888889      158813.666667     48     102   \n",
       "5_1               1.00        7446.888889      158845.666667     38      38   \n",
       "...                ...                ...                ...    ...     ...   \n",
       "3999_20-2         1.02      -18135.000000       10850.777778     45      44   \n",
       "4000_20-2         1.71      -18088.000000       10846.777778     60      35   \n",
       "4001_20-2         2.75      -19112.000000       10846.777778     99      36   \n",
       "4003_20-2         2.12      -19551.000000       10841.777778     55      26   \n",
       "4004_20-2         2.33      -17185.000000       10839.777778     49      21   \n",
       "\n",
       "           Mean.MembraneStain  Max.MembraneStain  Mean.PanCK  Max.PanCK  \\\n",
       "1_1                      3473               7354         715       5755   \n",
       "2_1                      3895              13832       18374      53158   \n",
       "3_1                      2892               6048        3265      37522   \n",
       "4_1                      6189              16091         485        964   \n",
       "5_1                      8138              19281         549        874   \n",
       "...                       ...                ...         ...        ...   \n",
       "3999_20-2                7430               9572         370        962   \n",
       "4000_20-2                8362              11209         161       2024   \n",
       "4001_20-2                5158              10180         634       2166   \n",
       "4003_20-2                6339               9804         211        570   \n",
       "4004_20-2                3491               5600         203        481   \n",
       "\n",
       "           Mean.CD45  ...                                 assay      organism  \\\n",
       "1_1              361  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "2_1              260  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "3_1              378  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "4_1              679  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "5_1              566  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "...              ...  ...                                   ...           ...   \n",
       "3999_20-2        450  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "4000_20-2        572  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "4001_20-2         41  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "4003_20-2        488  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "4004_20-2        335  ...  NanoString digital spatial profiling  Homo sapiens   \n",
       "\n",
       "              sex  tissue                      dataset             x  \\\n",
       "1_1        female    lung  nanostring_cosmx_human_lung   4215.888889   \n",
       "2_1        female    lung  nanostring_cosmx_human_lung   6092.888889   \n",
       "3_1        female    lung  nanostring_cosmx_human_lung   7214.888889   \n",
       "4_1        female    lung  nanostring_cosmx_human_lung   7418.888889   \n",
       "5_1        female    lung  nanostring_cosmx_human_lung   7446.888889   \n",
       "...           ...     ...                          ...           ...   \n",
       "3999_20-2    male    lung  nanostring_cosmx_human_lung -18135.000000   \n",
       "4000_20-2    male    lung  nanostring_cosmx_human_lung -18088.000000   \n",
       "4001_20-2    male    lung  nanostring_cosmx_human_lung -19112.000000   \n",
       "4003_20-2    male    lung  nanostring_cosmx_human_lung -19551.000000   \n",
       "4004_20-2    male    lung  nanostring_cosmx_human_lung -17185.000000   \n",
       "\n",
       "                       y  nicheformer_split _scvi_batch _scvi_labels  \n",
       "1_1        158847.666667              train           0            0  \n",
       "2_1        158834.666667              train           0            0  \n",
       "3_1        158843.666667              train           0            0  \n",
       "4_1        158813.666667              train           0            0  \n",
       "5_1        158845.666667              train           0            0  \n",
       "...                  ...                ...         ...          ...  \n",
       "3999_20-2   10850.777778              train           0            0  \n",
       "4000_20-2   10846.777778              train           0            0  \n",
       "4001_20-2   10846.777778              train           0            0  \n",
       "4003_20-2   10841.777778              train           0            0  \n",
       "4004_20-2   10839.777778              train           0            0  \n",
       "\n",
       "[771236 rows x 40 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2fe940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AspectRatio', 'CenterX_global_px', 'CenterY_global_px', 'Width',\n",
       "       'Height', 'Mean.MembraneStain', 'Max.MembraneStain', 'Mean.PanCK',\n",
       "       'Max.PanCK', 'Mean.CD45', 'Max.CD45', 'Mean.CD3', 'Max.CD3',\n",
       "       'Mean.DAPI', 'Max.DAPI', 'niche', 'image_id', 'cell_ID',\n",
       "       'sex_ontology_term_id', 'assay_ontology_term_id',\n",
       "       'organism_ontology_term_id', 'tissue_ontology_term_id',\n",
       "       'suspension_type', 'tissue_type', 'condition_id', 'sample_id',\n",
       "       'donor_id', 'author_cell_type', 'library_key', 'region', 'assay',\n",
       "       'organism', 'sex', 'tissue', 'dataset', 'x', 'y', 'nicheformer_split',\n",
       "       '_scvi_batch', '_scvi_labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92da800f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs['image_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d4200a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_subset8 = adata[adata.obs['image_id'] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b0689c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 81236 × 960\n",
       "    obs: 'AspectRatio', 'CenterX_global_px', 'CenterY_global_px', 'Width', 'Height', 'Mean.MembraneStain', 'Max.MembraneStain', 'Mean.PanCK', 'Max.PanCK', 'Mean.CD45', 'Max.CD45', 'Mean.CD3', 'Max.CD3', 'Mean.DAPI', 'Max.DAPI', 'niche', 'image_id', 'cell_ID', 'sex_ontology_term_id', 'assay_ontology_term_id', 'organism_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'tissue_type', 'condition_id', 'sample_id', 'donor_id', 'author_cell_type', 'library_key', 'region', 'assay', 'organism', 'sex', 'tissue', 'dataset', 'x', 'y', 'nicheformer_split', '_scvi_batch', '_scvi_labels'\n",
       "    var: 'level_0', 'index', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
       "    uns: '_scvi_manager_uuid', '_scvi_uuid', 'log1p', 'niche', 'nicheformer_version', 'schema_version', 'title'\n",
       "    obsm: 'X_niche_0', 'X_niche_1', 'X_niche_2', 'X_niche_3', 'X_niche_4', 'X_pca', 'X_scvi', 'spatial'\n",
       "    layers: 'log1p', 'raw'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_subset8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d7bebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 81236 × 960\n",
       "    obs: 'AspectRatio', 'CenterX_global_px', 'CenterY_global_px', 'Width', 'Height', 'Mean.MembraneStain', 'Max.MembraneStain', 'Mean.PanCK', 'Max.PanCK', 'Mean.CD45', 'Max.CD45', 'Mean.CD3', 'Max.CD3', 'Mean.DAPI', 'Max.DAPI', 'niche', 'image_id', 'cell_ID', 'sex_ontology_term_id', 'assay_ontology_term_id', 'organism_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'tissue_type', 'condition_id', 'sample_id', 'donor_id', 'author_cell_type', 'library_key', 'region', 'assay', 'organism', 'sex', 'tissue', 'dataset', 'x', 'y', 'nicheformer_split', '_scvi_batch', '_scvi_labels', 'shards'\n",
       "    var: 'level_0', 'index', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
       "    uns: '_scvi_manager_uuid', '_scvi_uuid', 'log1p', 'niche', 'nicheformer_version', 'schema_version', 'title'\n",
       "    obsm: 'X_niche_0', 'X_niche_1', 'X_niche_2', 'X_niche_3', 'X_niche_4', 'X_pca', 'X_scvi', 'spatial'\n",
       "    layers: 'log1p', 'raw'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
