{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f2a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# While we do find these useful to examine, we don't want to report them in the final\n",
    "# metrics as they do not necessarily represent biological concepts (as each amino acid\n",
    "# is just a single token).\n",
    "# concept_types_to_ignore = [\"amino_acid\"]\n",
    "\n",
    "\n",
    "def identify_top_feature_per_concept(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify the top feature per concept based on the maximum F1 score.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing F1 scores for each feature and concept\n",
    "\n",
    "    Returns:\n",
    "        DataFrame containing the top feature per concept\n",
    "    \"\"\"\n",
    "    # Get indices of feature concept pairs for best feature per concept\n",
    "    # df = df[\n",
    "    #     ~df[\"concept\"].str.contains(\n",
    "    #         \"|\".join(concept_types_to_ignore), case=False, na=False\n",
    "    #     )\n",
    "    # ]\n",
    "    top_feat_per_concept = df.sort_values(\n",
    "        by=[\"f1\"], ascending=False\n",
    "    ).drop_duplicates(\"concept\")\n",
    "    return top_feat_per_concept[[\"feature\", \"concept\"]]\n",
    "\n",
    "\n",
    "def identify_all_top_pairings(\n",
    "    df: pd.DataFrame, top_threshold: float = 0.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify all feature-concept pairs above a threshold F1 score.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing F1 scores for each feature and concept\n",
    "        top_threshold: Minimum F1 score threshold for considering a pairing\n",
    "\n",
    "    Returns:\n",
    "        DataFrame containing all feature-concept pairs above threshold\n",
    "    \"\"\"\n",
    "    # df = df[\n",
    "    #     ~df[\"concept\"].str.contains(\n",
    "    #         \"|\".join(concept_types_to_ignore), case=False, na=False\n",
    "    #     )\n",
    "    # ]\n",
    "\n",
    "    print(\n",
    "        f\"Compared {df['feature'].nunique():,} features (with 1+ true positive) to {df['concept'].nunique():,} concepts\"\n",
    "    )\n",
    "\n",
    "    top_feat_concept_pairs = (\n",
    "        df\n",
    "        .sort_values([\"f1\"], ascending=False)\n",
    "        .drop_duplicates(subset=[\"feature\", \"concept\"], keep=\"first\")\n",
    "    )\n",
    "    return top_feat_concept_pairs\n",
    "\n",
    "\n",
    "def find_top_heldout_feat_per_concept(\n",
    "    df_valid: pd.DataFrame, df_test: pd.DataFrame\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate the best F1 score per concept based on the held-out test set.\n",
    "\n",
    "    Args:\n",
    "        df_valid: DataFrame containing F1 scores for each feature and concept in the validation set\n",
    "        df_test: DataFrame containing F1 scores for each feature and concept in the test set\n",
    "\n",
    "    Returns:\n",
    "        Series containing best F1 scores per concept in test set\n",
    "    \"\"\"\n",
    "    top_feat_per_concept_valid = identify_top_feature_per_concept(df_valid)\n",
    "\n",
    "    # Merge test set with validation top pairs to get matching feature-concept pairs\n",
    "    matched_pairs = pd.merge(\n",
    "        df_test, top_feat_per_concept_valid, on=[\"feature\", \"concept\"], how=\"inner\"\n",
    "    )\n",
    "\n",
    "    return matched_pairs.sort_values(\n",
    "        [\"f1\"], ascending=False\n",
    "    ).drop_duplicates(subset=\"concept\", keep=\"first\")\n",
    "\n",
    "\n",
    "def find_all_top_heldout_feats(\n",
    "    df_valid: pd.DataFrame, df_test: pd.DataFrame, top_threshold: float = 0.5\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Calculate the number of top feature-concept pairs in the held-out test set.\n",
    "\n",
    "    Args:\n",
    "        df_valid: DataFrame containing F1 scores for each feature and concept in the validation set\n",
    "        df_test: DataFrame containing F1 scores for each feature and concept in the test set\n",
    "        top_threshold: Minimum F1 score threshold for considering a pairing\n",
    "\n",
    "    Returns:\n",
    "        Number of feature-concept pairs above threshold in test set\n",
    "    \"\"\"\n",
    "    top_feat_per_concept_valid = identify_all_top_pairings(df_valid, top_threshold)\n",
    "\n",
    "    # Merge test set with validation top pairs to get matching feature-concept pairs\n",
    "    matched_pairs = pd.merge(\n",
    "        df_test,\n",
    "        top_feat_per_concept_valid[[\"concept\", \"feature\"]],\n",
    "        on=[\"feature\", \"concept\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    # matched_pairs = matched_pairs[matched_pairs[\"f1_per_domain\"] > top_threshold]\n",
    "    matched_pairs = matched_pairs.sort_values(\n",
    "        [\"f1\"], ascending=False\n",
    "    ).drop_duplicates(subset=[\"feature\", \"concept\"], keep=\"first\")\n",
    "    return matched_pairs\n",
    "\n",
    "\n",
    "def report_metrics(\n",
    "    valid_path: Path, test_path: Path, top_threshold: float = 0.5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Report the best F1 scores per concept in the held-out test set.\n",
    "\n",
    "    Args:\n",
    "        valid_path: Path to validation F1 scores\n",
    "        test_path: Path to test F1 scores\n",
    "        top_threshold: Minimum F1 score threshold for considering a pairing\n",
    "    \"\"\"\n",
    "    df_valid = pd.read_csv(valid_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "\n",
    "    top_feat_per_concept_path = test_path.parent / \"heldout_top_pairings.csv\"\n",
    "    all_top_feats_path = test_path.parent / \"heldout_all_top_pairings.csv\"\n",
    "\n",
    "    top_feat_per_concept = find_top_heldout_feat_per_concept(df_valid, df_test)\n",
    "    top_feat_per_concept.to_csv(top_feat_per_concept_path, index=True, header=True)\n",
    "\n",
    "    all_top_feats = find_all_top_heldout_feats(df_valid, df_test, top_threshold)\n",
    "    all_top_feats.to_csv(all_top_feats_path, index=False, header=True)\n",
    "\n",
    "    print(\n",
    "        f\"Saved best pairings per concept to {top_feat_per_concept_path} and all top pairings to {all_top_feats_path}\"\n",
    "    )\n",
    "    print(\"-\" * 50)\n",
    "    print(\n",
    "        f\"Average best F1 per concept in test set: {top_feat_per_concept['f1'].mean():.3f}\"\n",
    "    )\n",
    "    print(f\"Number of concepts identified: {all_top_feats['concept'].nunique()}\")\n",
    "    print(\n",
    "        f\"Number of features associated with a concept: {all_top_feats['feature'].nunique()}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a779f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared 3,302 features (with 1+ true positive) to 1,793 concepts\n",
      "Saved best pairings per concept to /maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/output/test/heldout_top_pairings.csv and all top pairings to /maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/output/test/heldout_all_top_pairings.csv\n",
      "--------------------------------------------------\n",
      "Average best F1 per concept in test set: 0.369\n",
      "Number of concepts identified: 1793\n",
      "Number of features associated with a concept: 3136\n"
     ]
    }
   ],
   "source": [
    "valid_path=Path(\"/maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/output/valid/concept_f1_scores.csv\")\n",
    "test_path=Path(\"/maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/output/test/concept_f1_scores.csv\")\n",
    "\n",
    "report_metrics(valid_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb53ff",
   "metadata": {},
   "source": [
    "# for acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb11ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared 511 features (with 1+ true positive) to 1,793 concepts\n",
      "Saved best pairings per concept to /maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/output_acts/test/heldout_top_pairings.csv and all top pairings to /maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/output_acts/test/heldout_all_top_pairings.csv\n",
      "--------------------------------------------------\n",
      "Average best F1 per concept in test set: 0.139\n",
      "Number of concepts identified: 1793\n",
      "Number of features associated with a concept: 511\n"
     ]
    }
   ],
   "source": [
    "valid_path=Path(\"/maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/output_acts/valid/concept_f1_scores.csv\")\n",
    "test_path=Path(\"/maiziezhou_lab2/yunfei/Projects/interpTFM/activations_cosmx_lung_cancer/output_acts/test/concept_f1_scores.csv\")\n",
    "\n",
    "report_metrics(valid_path, test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
